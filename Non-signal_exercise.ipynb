{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-signal data exercise\n",
    "\n",
    "In this exercise you take on the role of a senior data analyst correcting mistakes made by a junior analyst. Your consulting company has received the MysteryData data set, and your goal is to build a classifier out of it, and evaluate how well the classifer works. You assigned the job to junior trainee Tux the Linux Penguin (who works for food).\n",
    "\n",
    "Tux is very excited to work on the data and has produced very promising results. What Tux does not yet know is that MysteryData is actually just random non-signal data where the features x and the class label y are independent of each other - it is not possible to learn anything meaningful from this data. Tux has never taken any of the UTU data analytics courses and has not noticed this. You should help Tux to correct the analyses, so you do not end up reporting incorrect results to your customers.\n",
    "\n",
    "You will write your answers inside this notebook. If all your answers are correct, your explanations thorough, and you solve the bonus questions, you will get a bonus point. Use written text, code, printouts or visualizations in you answers as needed. Return both this notebook filled (rename it lastname_firstname_studentid.ipynb), as well as a pdf export of the same notebook (same naming, but .pdf instead).\n",
    "\n",
    "The analysed problem is a binary classification task. We will follow the convention of using +1 to represent the positive class, and -1 the negative. In all but one task we will use area under ROC curve (AUC) to evaluate how well the classifier predicts. For binary classification tasks AUC and c-index are equivalent, 0.5 means random performance and 1.0 perfect predictions. The \"true\" AUC you would expect to see on a large enough sample of independent test data for any classifier trained on non-signal data is 0.5.\n",
    "\n",
    "Note that amount of samples, features, and class distribution for MysteryData can differ in different parts of the exercise (these are always written in comments above the code generating the data). Also, in one case there will be a data set on which it is possible to learn better than random classifier.\n",
    "\n",
    "Some notes on the codes:\n",
    "- we use predict_proba() instead of predict() when using AUC, because the predicted class probabilities are needed for computing AUC properly (predict() returns only +1/-1 values)\n",
    "- random seeds are fixed to guarantee that re-running the codes gives same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "#The data, trust me, you can't learn anything useful from this\n",
    "def load_mystery_data(samples, features, positives, random_seed):\n",
    "    #samples: sample size\n",
    "    #features: number of features\n",
    "    #positives: number of positive examples, positives <= samples\n",
    "    #random_seed: initializes the random generator\n",
    "    assert positives <= samples\n",
    "    rand_state = np.random.RandomState(random_seed)\n",
    "    #values in X are from normal distribution, with zero mean, unit variance, zero covariance\n",
    "    X = rand_state.randn(samples, features)\n",
    "    #y is a randomly shuffled vector of +1 and -1 values\n",
    "    y = np.hstack((np.ones(positives), -1.*np.ones(samples-positives)))\n",
    "    y = rand_state.permutation(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: some elementary mistakes\n",
    "\n",
    "## Lesson 1.1: never trust your ----- set performance\n",
    "\n",
    "The first analysis done by Tux contains an obvious elementary mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got area under ROC curve 0.885600\n",
      "Tux: \"I got very high AUC, problem solved!!\"\n"
     ]
    }
   ],
   "source": [
    "#100 samples, 100 features, 50 belong to positive class\n",
    "X, y = load_mystery_data(100, 100, 50, 2)\n",
    "\n",
    "#I am going to try knn on my data!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "learner = KNeighborsClassifier(n_neighbors=2)\n",
    "learner.fit(X, y)\n",
    "#get the estimated probability of belonging to class 1\n",
    "p = learner.predict_proba(X)[:,1]\n",
    "auc = roc_auc_score(y, p)\n",
    "print(\"I got area under ROC curve %f\" % auc)\n",
    "print('Tux: \"I got very high AUC, problem solved!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1\n",
    "Why can't you trust the AUC result of Tux?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we cant trust the AUC result of Tux is that this is a Non signal data and features are not related to target. \n",
    "Also, the Test set not isolated from the original dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your answer to question 1.1 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1.2: trivial baselines\n",
    "\n",
    "The second analysis done by Tux is done a bit better, but analysis of results contains another elementary mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.  0.  0.1 0.1 0.  0.2 0.1 0.1 0.1 0.  0.2 0.3 0.3 0.1 0.2 0.1\n",
      " 0.1 0.1 0.1 0.2 0.  0.1 0.  0.1 0.1 0.1 0.  0.1 0.1 0.  0.1 0.2 0.  0.1\n",
      " 0.2 0.  0.2 0.  0.2 0.1 0.  0.2 0.  0.1 0.  0.2 0.2 0.2 0.1 0.  0.1 0.2\n",
      " 0.1 0.2 0.  0.1 0.2 0.1 0.1 0.  0.1 0.1 0.1 0.  0.1 0.2 0.1 0.2 0.1 0.1\n",
      " 0.  0.1 0.5 0.4 0.1 0.1 0.1 0.  0.2 0.2 0.1 0.1 0.  0.1 0.1 0.2 0.  0.1\n",
      " 0.1 0.2 0.1 0.  0.1 0.2 0.3 0.  0.  0.3 0.3 0.  0.  0.  0.1 0.2 0.  0.1\n",
      " 0.1 0.1 0.2 0.1 0.  0.1 0.  0.  0.  0.1 0.1 0.  0.1 0.  0.3 0.2 0.1 0.2\n",
      " 0.1 0.1 0.1 0.2 0.1 0.3 0.1 0.1 0.1 0.2 0.1 0.  0.  0.2 0.  0.1 0.  0.1\n",
      " 0.  0.1 0.1 0.  0.1 0.2 0.1 0.1 0.1 0.3 0.2 0.4 0.1 0.  0.  0.1 0.2 0.\n",
      " 0.1 0.  0.1 0.1 0.  0.1 0.1 0.  0.  0.  0.1 0.1 0.  0.2 0.  0.1 0.2 0.\n",
      " 0.2 0.  0.2 0.2 0.  0.1 0.1 0.1 0.  0.2 0.2 0.1 0.  0.1 0.1 0.3 0.2 0.2\n",
      " 0.1 0.  0.3 0.1 0.1 0.2 0.1 0.  0.  0.  0.1 0.  0.2 0.  0.1 0.  0.1 0.\n",
      " 0.  0.2 0.1 0.  0.  0.  0.  0.2 0.3 0.  0.2 0.2 0.  0.3 0.1 0.  0.2 0.2\n",
      " 0.1 0.1 0.1 0.3 0.3 0.1 0.  0.1 0.1 0.3 0.1 0.2 0.  0.2 0.2 0.3 0.1 0.1\n",
      " 0.2 0.1 0.  0.1 0.  0.  0.2 0.3 0.  0.  0.2 0.2 0.1 0.  0.1 0.2 0.  0.1\n",
      " 0.1 0.2 0.1 0.1 0.3 0.  0.1 0.  0.2 0.1 0.2 0.1 0.2 0.1 0.  0.2 0.  0.\n",
      " 0.1 0.1 0.4 0.1 0.1 0.2 0.  0.2 0.1 0.  0.2 0.1 0.1 0.  0.  0.1 0.2 0.2\n",
      " 0.  0.  0.2 0.  0.1 0.2 0.2 0.  0.2 0.2 0.  0.1 0.1 0.  0.  0.  0.1 0.1\n",
      " 0.  0.2 0.  0.1 0.2 0.2]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1.]\n",
      "0.5823895520865219\n",
      "Classification accuracy: 0.900000\n",
      "Tux: \"I got 90% classification accuracy, problem solved!!\"\"\n"
     ]
    }
   ],
   "source": [
    "#1000 samples, 100 features, 100 belong to positive class\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "X, y = load_mystery_data(1000, 100, 100, 1)\n",
    "\n",
    "#I am going to try knn on my data!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Instead of AUC I will use classification accuracy!\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Now I use a separate test set!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, stratify=y, random_state=1)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "p_test = knn.predict(X_test)\n",
    "prob=knn.predict_proba(X_test)[:,1]\n",
    "print (prob)\n",
    "\n",
    "\n",
    "print(p_test)\n",
    "accuracy = accuracy_score(y_test, p_test)\n",
    "#conf_mat=confusion_matrix(y_test,p_test)\n",
    "roc=roc_auc_score(y_test,prob)\n",
    "#print(conf_mat)\n",
    "print (roc)\n",
    "print(\"Classification accuracy: %f\" %accuracy)\n",
    "print('Tux: \"I got 90% classification accuracy, problem solved!!\"\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2\n",
    "1. Does the high classification accuracy really mean that this is a good predictor?\n",
    "2. Look at the test set predictions in p_test, what has this classifier actually learned?\n",
    "3. What would the results look like if you used AUC instead of classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your answer to question 1.2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No. Correspondingly the AUC should also be high\n",
    "2. We can say looking at p_test, the classifier is classifying mostly the majority class. \n",
    "3. Since AUC is around 0,5, even though the accuracy is high, we cannot trust the result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: introduction to permutation tests\n",
    "\n",
    "Next, we are using permutation tests to estimate, how likely we are to see AUC values as high as observed, if y is independent of x (non-signal data).\n",
    "\n",
    "The test is implemented as follows:\n",
    "- let AUC_original be the AUC obtained in the original analysis\n",
    "- For 1000 (or preferably more if you have enough CPU time to use) repetitions, shuffle the labels in y, then run the analysis again and compute the AUC value. Store all 1000 AUC values in a list.\n",
    "- Visualization: visualize the permutation distribution by plotting a histogram of the 1000 AUC values. Does AUC_original look like an outlier, or do you often get as good or better results with permuted class labels?\n",
    "- p-value: relative fraction of runs, where obtained AUC $\\geq$ AUC_original\n",
    "- example: AUC with original class labeling is 0.6. In 70 runs out of 1000, we obtain as high as or larger AUC. p-value is then $\\frac{70}{1000} = 0.07$ \n",
    "- result is considered statistically significant, if $p<\\alpha$, where $\\alpha$ a pre-specified significance level (often $\\alpha=0.05$ or $\\alpha=0.01$). Statistical significance does not mean that the results are good, only that the classifier has likely learned something from the data. In the following experiments, use $\\alpha=0.05$.\n",
    "\n",
    "## Lesson 2.1: sample size\n",
    "\n",
    "Tux is now analyzing a small data set with 5-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.700000\n",
      "Tux: \"I did proper cross-validation and got better than random results. My classifier learned something!!\"\n"
     ]
    }
   ],
   "source": [
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "auc = np.mean(cv_aucs)\n",
    "print(\"AUC: %f\" %auc)\n",
    "print('Tux: \"I did proper cross-validation and got better than random results. My classifier learned something!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "Implement a permutation test for the above analysis, are these results statistically significant with $\\alpha=0.05$? Provide both visualization of the permutation distribution, as well as the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuting and running\n",
      "The result is not statistically significant\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.shuffle(y)\n",
    "aucperm=[]  #To store the AUC score after permutation\n",
    "p_counts =  0\n",
    "print ('Permuting and running')\n",
    "for i in range (1000): #Permute 1000 times\n",
    "    y = np.random.permutation(y)\n",
    "    cv_aucs = [] #Each CV score.\n",
    "    for train, test in cv.split(X, y):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    \n",
    "    auc = np.mean(cv_aucs)\n",
    "    aucperm.append(auc)\n",
    "\n",
    "    #check original auc with current auc\n",
    "    if auc >= 0.7:\n",
    "        p_counts+=1\n",
    "    p_val=p_counts/1000\n",
    "if p_val < 0.05:\n",
    "    print ('Classifier learnt something from the data')\n",
    "else:\n",
    "    print ('The result is not statistically significant')\n",
    "    \n",
    "plt.figure()\n",
    "axes=plt.gca()  \n",
    "\n",
    "plt.hist(aucperm)\n",
    "ylim=axes.get_ylim()\n",
    "plt.xlabel('AUC score')\n",
    "plt.ylabel('Permutation frequency')\n",
    "plt.plot([.7,.7],ylim,'--g',linewidth=2,label='Original Auc') #0.7 is the auc obtained by Tux\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization we can see that the p value is greater than .7 and so the result is not statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2.2: sample size again\n",
    "\n",
    "Let's give poor Tux a better data set that actually has clear difference between the classes and see how things work out. (on this data it is possible to obtain true AUC larger than 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_new_mystery_data(samples, features, positives, random_seed):\n",
    "    #samples: sample size\n",
    "    #features: number of positive examples, positives <= samples\n",
    "    #random_seed: initializes the random generator\n",
    "    assert positives <= samples\n",
    "    rand_state = np.random.RandomState(random_seed)\n",
    "    #values in X are from normal distribution, with zero mean, unit variance, zero covariance\n",
    "    X_pos = rand_state.randn(positives, features)\n",
    "    X_neg = rand_state.randn(samples-positives, features)+0.65\n",
    "    X = np.vstack((X_pos, X_neg))\n",
    "    #y is a randomly shuffled vector of +1 and -1 values\n",
    "    y = np.hstack((np.ones(positives), -1.*np.ones(samples-positives)))\n",
    "    I = rand_state.permutation(samples)\n",
    "    X = X[I]\n",
    "    y = y[I]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
      " -1.  1.]\n",
      "[[ 1.16071441  1.06429764  1.99454942  1.14351532  0.41299582  0.70728515\n",
      "  -0.05707145  1.19666484  1.59250041 -2.32959677]\n",
      " [-1.97772828 -1.7433723   0.26607016  2.38496733  1.12369125  1.67262221\n",
      "   0.09914922  1.39799638 -0.27124799  0.61320418]\n",
      " [-0.77088052 -0.02894677  1.18388481  1.3939744   2.87504964  0.76718142\n",
      "   0.89461452  0.47270118  0.24427047  1.43177519]\n",
      " [ 0.07688664 -0.67044755  1.88620533  3.11532508  2.03323223  0.99623312\n",
      "   1.67251611  0.81681027  2.30671662  1.31788961]\n",
      " [-0.23218226 -0.5017289   1.12878515 -0.69781003 -0.08112218 -0.52929608\n",
      "   1.04618286 -1.41855603 -0.36249918 -0.12190569]\n",
      " [ 0.42005336 -0.47955119  0.0100374   0.96383052 -0.57583598  0.42820686\n",
      "   1.98992631  0.67930971  2.63538575  2.0971656 ]\n",
      " [ 0.94294072  0.17919275  3.05432561 -0.08935674  0.33717124  0.30111808\n",
      "   0.21097376  0.79110417  0.92304932 -0.96857075]\n",
      " [ 0.36237059 -0.70931057  0.60195867  0.16921266  1.02775309  2.26440797\n",
      "  -0.47310404  0.26127205  0.98234995  1.78497317]\n",
      " [ 0.66023155 -0.35087189 -0.93943336 -0.48933722 -0.80459114 -0.21269764\n",
      "  -0.33914025  0.31216994  0.56515267 -0.14742026]\n",
      " [-0.02590534  0.2890942  -0.53987907  0.70816002  0.84222474  0.2035808\n",
      "   2.39470366  0.91745894 -0.11227247 -0.36218045]\n",
      " [ 0.43302619  1.20303737 -0.96506567  1.02827408  0.22863013  0.44513761\n",
      "  -1.13660221  0.13513688  1.484537   -1.07980489]\n",
      " [ 1.98508459  1.74481415 -1.85618548 -0.2227737  -0.06584785 -2.13171211\n",
      "  -0.04883051  0.39334122  0.21726515 -1.99439377]\n",
      " [ 1.3315865   0.71527897 -1.54540029 -0.00838385  0.62133597 -0.72008556\n",
      "   0.26551159  0.10854853  0.00429143 -0.17460021]\n",
      " [-0.26731719 -0.54930901  0.1327083  -0.47614201  1.30847308  0.19501328\n",
      "   0.40020999 -0.33763234  1.25647226 -0.7319695 ]\n",
      " [ 1.00347761  0.44272051 -0.42969738  0.52693017  0.25901781  1.90517373\n",
      "   1.59712608 -0.37231069  1.81716837  0.07802319]\n",
      " [ 0.31935642  0.4609029  -0.21578989  0.98907246  0.31475378  2.46765106\n",
      "  -1.50832149  0.62060066 -1.04513254 -0.79800882]\n",
      " [ 0.76747566 -1.25745689 -0.27290926  1.11975143  0.50563324  0.24986165\n",
      "   0.35401615  1.49820861  1.35683045 -0.13726893]\n",
      " [-1.0610712   1.26229731  1.75012937  1.21435253 -0.06279944  0.38914052\n",
      "   1.19842807  1.25319905  1.65686114  0.35557399]\n",
      " [ 1.86814885  0.59347928  1.11088845  1.31237401 -1.64510333 -0.54592931\n",
      "   0.31689884 -0.14139077  0.92417278  0.13509008]\n",
      " [ 1.10770823  0.24454398 -0.06191203 -0.75389296  0.71195902  0.91826915\n",
      "  -0.48209314  0.08958761  0.82699862 -1.95451212]]\n",
      "AUC: 0.875000\n",
      "Tux: \"Not sure if I can trust the results anymore, my data set is really small! Please help me compute the p-value!!\"\n"
     ]
    }
   ],
   "source": [
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_new_mystery_data(20, 10, 10, 10)\n",
    "print (y)\n",
    "print (X)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print(\"AUC: %f\" %cv_auc)\n",
    "print('Tux: \"Not sure if I can trust the results anymore, my data set is really small! Please help me compute the p-value!!\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier learnt something from the data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.shuffle(y)\n",
    "aucperm=[] #CV scores \n",
    "p_counts =  0 #Probability count\n",
    "for i in range (1000):\n",
    "    y = np.random.permutation(y)\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X, y):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    \n",
    "    auc = np.mean(cv_aucs)\n",
    "    aucperm.append(auc)\n",
    "\n",
    "    #check original auc with current auc\n",
    "    if auc >= 0.87:\n",
    "        p_counts+=1\n",
    "    p_val=p_counts/1000\n",
    "if p_val < 0.05:\n",
    "    print ('Classifier learnt something from the data')\n",
    "else:\n",
    "    print ('The result is not statistically significant')\n",
    "    \n",
    "plt.figure()\n",
    "axes=plt.gca()  \n",
    "#plt.plot([],aucperm,label='Actual AUC')\n",
    "\n",
    "plt.hist(aucperm)\n",
    "ylim=axes.get_ylim()\n",
    "plt.xlabel('AUC score')\n",
    "plt.ylabel('Permutation frequency')\n",
    "plt.plot([.87,.87],ylim,'--g',linewidth=2,label='Original Auc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print (p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "Implement a permutation test for the above analysis, are these results statistically significant with $\\alpha=0.05$? Provide both visualization of the permutation distribution, as well as the p-value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that p value is less than the alpha. So the model is likely to have learnt better than before "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: mis-using feature selection\n",
    "\n",
    "Here is a very simple correlation based feature selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "def select(X, Y, scount):\n",
    "    #select scount features from X with highest correlation with Y\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = kendalltau(X[:,i], Y)[0]\n",
    "\n",
    "        correlations.append(np.abs(corr))\n",
    "    correlations = np.array(correlations)\n",
    "    I = np.argsort(correlations)\n",
    "    #break\n",
    "    I = I[::-1]\n",
    "\n",
    "    return X[:,I[:scount]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tux: \"My CV-AUC before feature selection is 0.496000\"\n",
      "Tux: \"My CV-AUC after feature selection is 0.808000, it really works!!\"\n"
     ]
    }
   ],
   "source": [
    "#50 samples, 1000 features, 25 belong to positive class\n",
    "X, y = load_mystery_data(50, 1000, 25, 1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC before feature selection is %f\"' %cv_auc)\n",
    "\n",
    "\n",
    "#I'm going to improve my AUC with feature selection!!!\n",
    "X_fs = select(X, y, 5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X_fs, y):\n",
    "    X_train = X_fs[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X_fs[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC after feature selection is %f, it really works!!\"' %cv_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1\n",
    "\n",
    "Use permutation test to show Tux that the feature selection based classification approach is actually not learning anything from the data ($\\alpha=0.05$, provide both visualization of the permutation distribution, as well as the p-value). Running the test may take a while. Analyse what is going on here, why did the results look so good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is not statistically significant\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.shuffle(y)\n",
    "aucperm=[]  #To store the auc scores for each permutation. \n",
    "p_counts =  0\n",
    "\n",
    "\n",
    "for i in range (1000):\n",
    "    y = np.random.permutation(y)\n",
    "    X_fs = select(X, y, 5)\n",
    "\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X_fs, y):\n",
    "        X_train = X_fs[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X_fs[test]\n",
    "        y_test = y[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    \n",
    "    auc = np.mean(cv_aucs)\n",
    "    aucperm.append(auc)\n",
    "\n",
    "    #check original auc with current auc\n",
    "    if auc >= 0.808:\n",
    "        p_counts+=1\n",
    "    p_val=p_counts/1000 #fraction of permuted tests greater than original auc\n",
    "if p_val < 0.05:\n",
    "    print ('Classifier learnt something from the data')\n",
    "else:\n",
    "    print ('The result is not statistically significant')\n",
    "    \n",
    "plt.figure()\n",
    "axes=plt.gca()  \n",
    "\n",
    "plt.hist(aucperm)\n",
    "ylim=axes.get_ylim()\n",
    "plt.xlabel('AUC score')\n",
    "plt.ylabel('Permutation frequency')\n",
    "plt.plot([.808,.808],ylim,'--r',linewidth=2,label='Original Auc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print (p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the feature selection before CV. Since the p value obtained is greater than alpha value, we conclude that the result is not statistically significant. \n",
    "Tux had done feature selection before CV, which is not reliable approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2 (bonus exercise)\n",
    "\n",
    "Correct the bias in above example by combining feature selection properly with cross-validation, run the experiment again. Do also a permutation test for this experiment with as many permutations as you can afford in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_index(X,Y,scount):\n",
    "\n",
    "    #select scount features from X with highest correlation with Y\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = kendalltau(X[:,i], Y)[0]\n",
    "\n",
    "        correlations.append(np.abs(corr))\n",
    "    correlations = np.array(correlations)\n",
    "    I = np.argsort(correlations)\n",
    "    #break\n",
    "    I = I[::-1] ##Take indexes of only the highest correlated features. \n",
    "\n",
    "    return I[:scount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492\n",
      "The result is not statistically significant\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#np.random.shuffle(y)\n",
    "aucperm=[]\n",
    "run_counts =  0\n",
    "\n",
    "X, y = load_mystery_data(50, 1000, 25, 1)\n",
    "\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "        \n",
    "    #Column index for selected features\n",
    "    index=select_index(X_train,y_train,5)\n",
    "    X_train=X_train[:,index]#for the CV (5 only)\n",
    "    X_test=X_test[:,index]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "    \n",
    "auc = np.mean(cv_aucs)\n",
    "print (auc)\n",
    "\n",
    "\n",
    "for i in range (100):\n",
    "    y = np.random.permutation(y)\n",
    "    #X_fs = select(X, y, 5)\n",
    "\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X, y):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        \n",
    "        #Column index for selected features\n",
    "        index=select_index(X_train,y_train,5)\n",
    "        X_train=X_train[:,index]#for the CV\n",
    "        X_test=X_test[:,index]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1] #probability for class 1 (positive)\n",
    "        auc_p = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc_p)\n",
    "    \n",
    "    auc_p = np.mean(cv_aucs)\n",
    "    aucperm.append(auc_p)\n",
    "\n",
    "    #compare auc of permuted test and without permuted\n",
    "    if auc_p >= auc:\n",
    "        run_counts+=1\n",
    "    p_val=run_counts/100 #fraction of permuted tests greater than original auc\n",
    "    \n",
    "#Checking significant threshold\n",
    "if p_val < 0.05:\n",
    "    print ('Classifier learnt something from the data')\n",
    "else:\n",
    "    print ('The result is not statistically significant')\n",
    "    \n",
    "plt.figure()\n",
    "axes=plt.gca()  \n",
    "\n",
    "plt.hist(aucperm)\n",
    "ylim=axes.get_ylim()\n",
    "plt.xlabel('AUC score')\n",
    "plt.ylabel('Permutation frequency')\n",
    "plt.plot([auc,auc],ylim,'--r',linewidth=2,label='Original Auc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print (p_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try CV without permutation, we get the auc score around 0,5. With permutation, we can see that the model cannot learn well from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
